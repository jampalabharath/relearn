<!DOCTYPE html>
<html lang="en-us" dir="ltr" itemscope itemtype="http://schema.org/Article" data-r-output-format="print">
  <head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
    <meta charset="utf-8">
    <meta name="viewport" content="height=device-height, width=device-width, initial-scale=1.0, minimum-scale=1.0">
    <meta name="generator" content="Hugo 0.148.2">
    <meta name="generator" content="Relearn 8.0.0+9803d5122ebb3276acea823f476e9eb44f607862">
    <meta name="description" content="Basic Aggregate Functions Sample Data from pyspark.sql import Row # Create sample data data = [ Row(id=1, value=10), Row(id=2, value=20), Row(id=3, value=30), Row(id=4, value=None), Row(id=5, value=40), Row(id=6, value=20) ] # Create DataFrame df = spark.createDataFrame(data) # Show the DataFrame df.show() Aggregate Functions in PySpark Summation (sum) â€“ Adds up the values in a column. Average (avg) â€“ Computes the average of values in a column. Count (count) â€“ Counts the number of non-null values in a column. Maximum (max) / Minimum (min) â€“ Finds the highest and lowest values. Distinct Count (countDistinct) â€“ Counts unique values in a column. Notes Handling Nulls:">
    <meta name="author" content="">
    <meta name="twitter:card" content="summary">
    <meta name="twitter:title" content="Aggregate functions :: Data Engineering Notes">
    <meta name="twitter:description" content="Basic Aggregate Functions Sample Data from pyspark.sql import Row # Create sample data data = [ Row(id=1, value=10), Row(id=2, value=20), Row(id=3, value=30), Row(id=4, value=None), Row(id=5, value=40), Row(id=6, value=20) ] # Create DataFrame df = spark.createDataFrame(data) # Show the DataFrame df.show() Aggregate Functions in PySpark Summation (sum) â€“ Adds up the values in a column. Average (avg) â€“ Computes the average of values in a column. Count (count) â€“ Counts the number of non-null values in a column. Maximum (max) / Minimum (min) â€“ Finds the highest and lowest values. Distinct Count (countDistinct) â€“ Counts unique values in a column. Notes Handling Nulls:">
    <meta property="og:url" content="http://localhost:1313/azure_data_bricks/aggregations/">
    <meta property="og:site_name" content="Data Engineering Notes">
    <meta property="og:title" content="Aggregate functions :: Data Engineering Notes">
    <meta property="og:description" content="Basic Aggregate Functions Sample Data from pyspark.sql import Row # Create sample data data = [ Row(id=1, value=10), Row(id=2, value=20), Row(id=3, value=30), Row(id=4, value=None), Row(id=5, value=40), Row(id=6, value=20) ] # Create DataFrame df = spark.createDataFrame(data) # Show the DataFrame df.show() Aggregate Functions in PySpark Summation (sum) â€“ Adds up the values in a column. Average (avg) â€“ Computes the average of values in a column. Count (count) â€“ Counts the number of non-null values in a column. Maximum (max) / Minimum (min) â€“ Finds the highest and lowest values. Distinct Count (countDistinct) â€“ Counts unique values in a column. Notes Handling Nulls:">
    <meta property="og:locale" content="en_us">
    <meta property="og:type" content="article">
    <meta property="article:section" content="Azure Data Bricks">
    <meta itemprop="name" content="Aggregate functions :: Data Engineering Notes">
    <meta itemprop="description" content="Basic Aggregate Functions Sample Data from pyspark.sql import Row # Create sample data data = [ Row(id=1, value=10), Row(id=2, value=20), Row(id=3, value=30), Row(id=4, value=None), Row(id=5, value=40), Row(id=6, value=20) ] # Create DataFrame df = spark.createDataFrame(data) # Show the DataFrame df.show() Aggregate Functions in PySpark Summation (sum) â€“ Adds up the values in a column. Average (avg) â€“ Computes the average of values in a column. Count (count) â€“ Counts the number of non-null values in a column. Maximum (max) / Minimum (min) â€“ Finds the highest and lowest values. Distinct Count (countDistinct) â€“ Counts unique values in a column. Notes Handling Nulls:">
    <meta itemprop="wordCount" content="433">
    <title>Aggregate functions :: Data Engineering Notes</title>
    <link href="http://localhost:1313/azure_data_bricks/aggregations/" rel="canonical" type="text/html" title="Aggregate functions :: Data Engineering Notes">
    <link href="/azure_data_bricks/aggregations/index.md" rel="alternate" type="text/markdown" title="Aggregate functions :: Data Engineering Notes">
    <link href="/images/favicon.ico?1759986780" rel="icon" type="image/x-icon" sizes="any">
    <link href="/css/auto-complete/auto-complete.min.css?1759986780" rel="stylesheet">
    <script src="/js/auto-complete/auto-complete.min.js?1759986780" defer></script>
    <script src="/js/search-lunr.js?1759986780" defer></script>
    <script src="/js/search.js?1759986780" defer></script>
    <script>
      window.relearn = window.relearn || {};
      window.relearn.index_js_url="/searchindex.en.js?1759986780";
    </script>
    <script src="/js/lunr/lunr.min.js?1759986780" defer></script>
    <script src="/js/lunr/lunr.stemmer.support.min.js?1759986780" defer></script>
    <script src="/js/lunr/lunr.multi.min.js?1759986780" defer></script>
    <script src="/js/lunr/lunr.en.min.js?1759986780" defer></script>
    <script>
      window.relearn = window.relearn || {};
      window.relearn.contentLangs=['en'];
    </script>
    <link href="/fonts/fontawesome/css/fontawesome-all.min.css?1759986780" rel="stylesheet" media="print" onload="this.media='all';this.onload=null;"><noscript><link href="/fonts/fontawesome/css/fontawesome-all.min.css?1759986780" rel="stylesheet"></noscript>
    <link href="/css/perfect-scrollbar/perfect-scrollbar.min.css?1759986780" rel="stylesheet">
    <link href="/css/theme.css?1759986780" rel="stylesheet">
    <link href="/css/format-print.css?1759986780" rel="stylesheet" id="R-format-style">
    <script>
      window.relearn = window.relearn || {};
      // configuration
      window.relearn.min = ``;
      window.relearn.path='\/azure_data_bricks\/aggregations\/';
      window.relearn.relBasePath='..\/..';
      window.relearn.relBaseUri='..\/..';
      window.relearn.absBaseUri='http:\/\/localhost:1313';
      window.relearn.disableAnchorCopy=false;
      window.relearn.disableAnchorScrolling=false;
      window.relearn.disableInlineCopyToClipboard=false;
      window.relearn.enableBlockCodeWrap=true;
      // legal
      window.relearn.getItem = (s,n) => {return s.getItem(n)};
      window.relearn.setItem = (s,n,v) => {return s.setItem(n,v)};
      window.relearn.removeItem = (s,n) => {return s.removeItem(n)};
      // translations
      window.T_Copy_to_clipboard = `Copy to clipboard`;
      window.T_Copied_to_clipboard = `Copied to clipboard!`;
      window.T_Copy_link_to_clipboard = `Copy link to clipboard`;
      window.T_Link_copied_to_clipboard = `Copied link to clipboard!`;
      window.T_Reset_view = `Reset view`;
      window.T_View_reset = `View reset!`;
      window.T_No_results_found = `No results found for "{0}"`;
      window.T_N_results_found = `{1} results found for "{0}"`;
      // variant stuff
      window.relearn.themevariants = [ 'auto', 'zen-light', 'zen-dark' ];
      window.relearn.customvariantname = "my-custom-variant";
      window.relearn.changeVariant = function(variant) {
        var oldVariant = document.documentElement.dataset.rThemeVariant;
        window.relearn.setItem(window.localStorage, window.relearn.absBaseUri + "/variant", variant);
        document.documentElement.dataset.rThemeVariant = variant;
        if (oldVariant != variant) {
          document.dispatchEvent( new CustomEvent('themeVariantLoaded', { detail: { variant, oldVariant } }) );
          window.relearn.markVariant();
        }
      }
      window.relearn.markVariant = function() {
        var variant = window.relearn.getItem(window.localStorage, window.relearn.absBaseUri + "/variant");
        document.querySelectorAll(".R-variantswitcher select").forEach((select) => {select.value = variant;});
      }
      window.relearn.initVariant = function() {
        var variant = window.relearn.getItem(window.localStorage, window.relearn.absBaseUri + "/variant") ?? "";
        if( variant == window.relearn.customvariantname ){
        }else if( !variant || !window.relearn.themevariants.includes(variant) ){
          variant = window.relearn.themevariants[0];
          window.relearn.setItem(window.localStorage, window.relearn.absBaseUri + "/variant", variant);
        }
        document.documentElement.dataset.rThemeVariant = variant;
      }
      window.relearn.initVariant();
      window.relearn.markVariant();
    </script><style>
:root {
    --MENU-WIDTH-S: 14.375rem;
    --MENU-WIDTH-M: 14.375rem;
    --MENU-WIDTH-L: 18.75rem;
    --MAIN-WIDTH-MAX: 1000rem;
}
</style>
  </head>
  <body class="mobile-support print" data-url="/azure_data_bricks/aggregations/">
    <div id="R-body" class="default-animation">
      <div id="R-body-overlay"></div>
      <nav id="R-topbar">
        <div class="topbar-wrapper">
          <div class="topbar-sidebar-divider"></div>
          <div class="topbar-area topbar-area-start" data-area="start">
            <div class="topbar-button topbar-button-sidebar" data-content-empty="disable" data-width-s="show" data-width-m="hide" data-width-l="hide"><button class="topbar-control" onclick="toggleNav()" type="button" title="Menu (CTRL&#43;ALT&#43;n)"><i class="fa-fw fas fa-bars"></i></button>
            </div>
            <div class="topbar-button topbar-button-toc" data-content-empty="hide" data-width-s="show" data-width-m="show" data-width-l="show"><button class="topbar-control" onclick="toggleTopbarFlyout(this)" type="button" title="Table of Contents (CTRL&#43;ALT&#43;t)"><i class="fa-fw fas fa-list-alt"></i></button>
              <div class="topbar-content">
                <div class="topbar-content-wrapper">
<nav class="TableOfContents">
  <ul>
    <li><a href="#basic-aggregate-functions">Basic Aggregate Functions</a>
      <ul>
        <li><a href="#sample-data">Sample Data</a></li>
        <li><a href="#aggregate-functions-in-pyspark">Aggregate Functions in PySpark</a></li>
        <li><a href="#notes">Notes</a></li>
      </ul>
    </li>
    <li><a href="#advanced-aggregation-functions">Advanced Aggregation Functions</a>
      <ul>
        <li><a href="#sample-data-1">Sample Data</a></li>
        <li><a href="#1-grouped-aggregation">1. Grouped Aggregation</a></li>
        <li><a href="#2-multiple-aggregations">2. Multiple Aggregations</a></li>
        <li><a href="#3-concatenate-strings">3. Concatenate Strings</a></li>
        <li><a href="#4-first-and-last">4. First and Last</a></li>
        <li><a href="#5-standard-deviation-and-variance">5. Standard Deviation and Variance</a></li>
        <li><a href="#6-aggregation-with-alias">6. Aggregation with Alias</a></li>
        <li><a href="#7-sum-of-distinct-values">7. Sum of Distinct Values</a></li>
        <li><a href="#-summary">ðŸ“Œ Summary</a></li>
      </ul>
    </li>
  </ul>
</nav>
                </div>
              </div>
            </div>
          </div>
          <ol class="topbar-breadcrumbs breadcrumbs highlightable" itemscope itemtype="http://schema.org/BreadcrumbList"><li itemscope itemtype="https://schema.org/ListItem" itemprop="itemListElement" class="a11y-only"><a itemprop="item" href="/"><span itemprop="name">Data Engineering Notes</span></a><meta itemprop="position" content="1">&nbsp;/&nbsp;</li><li itemscope itemtype="https://schema.org/ListItem" itemprop="itemListElement" class=""><a itemprop="item" href="/azure_data_bricks/"><span itemprop="name">ADB</span></a><meta itemprop="position" content="2">&nbsp;/&nbsp;</li><li itemscope itemtype="https://schema.org/ListItem" itemprop="itemListElement" class=""><span itemprop="name">Aggregate functions</span><meta itemprop="position" content="3"></li>
          </ol>
          <div class="topbar-area topbar-area-end" data-area="end">
            <div class="topbar-button topbar-button-edit" data-content-empty="disable" data-width-s="area-more" data-width-m="show" data-width-l="show"><a class="topbar-control" href="https://github.com/jampalabharath/relearn/tree/main/content/Azure_Data_Bricks/Aggregations.md" rel="external" target="_blank" title="Edit (CTRL+ALT+w)"><i class="fa-fw fas fa-pen"></i></a>
            </div>
            <div class="topbar-button topbar-button-markdown" data-content-empty="disable" data-width-s="area-more" data-width-m="show" data-width-l="show"><a class="topbar-control" href="/azure_data_bricks/aggregations/index.md" title="Show Markdown"><i class="fa-fw fab fa-markdown"></i></a>
            </div>
            <div class="topbar-button topbar-button-print" data-content-empty="disable" data-width-s="area-more" data-width-m="show" data-width-l="show"><a class="topbar-control" href="/azure_data_bricks/aggregations/index.print.html" title="Print whole chapter (CTRL+ALT+p)"><i class="fa-fw fas fa-print"></i></a>
            </div>
            <div class="topbar-button topbar-button-prev" data-content-empty="disable" data-width-s="show" data-width-m="show" data-width-l="show"><a class="topbar-control" href="/azure_data_bricks/nulls/" title="Handling Nulls (ðŸ¡)"><i class="fa-fw fas fa-chevron-left"></i></a>
            </div>
            <div class="topbar-button topbar-button-next" data-content-empty="disable" data-width-s="show" data-width-m="show" data-width-l="show"><a class="topbar-control" href="/azure_data_bricks/joins/" title="Joins (ðŸ¡’)"><i class="fa-fw fas fa-chevron-right"></i></a>
            </div>
            <div class="topbar-button topbar-button-more" data-content-empty="hide" data-width-s="show" data-width-m="show" data-width-l="show"><button class="topbar-control" onclick="toggleTopbarFlyout(this)" type="button" title="More"><i class="fa-fw fas fa-ellipsis-v"></i></button>
              <div class="topbar-content">
                <div class="topbar-content-wrapper">
                  <div class="topbar-area topbar-area-more" data-area="more">
                  </div>
                </div>
              </div>
            </div>
          </div>
        </div>
      </nav>
      <div id="R-main-overlay"></div>
      <main id="R-body-inner" class="highlightable azure_data_bricks" tabindex="-1">
        <div class="flex-block-wrapper">
<article class="default">
  <header class="headline">
  </header>

<h1 id="aggregate-functions">Aggregate functions</h1>

<h2 id="basic-aggregate-functions">Basic Aggregate Functions</h2>
<h3 id="sample-data">Sample Data</h3>
<div class="highlight wrap-code" dir="auto"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">pyspark.sql</span> <span class="kn">import</span> <span class="n">Row</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Create sample data</span>
</span></span><span class="line"><span class="cl"><span class="n">data</span> <span class="o">=</span> <span class="p">[</span>
</span></span><span class="line"><span class="cl">    <span class="n">Row</span><span class="p">(</span><span class="nb">id</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="mi">10</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">    <span class="n">Row</span><span class="p">(</span><span class="nb">id</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="mi">20</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">    <span class="n">Row</span><span class="p">(</span><span class="nb">id</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="mi">30</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">    <span class="n">Row</span><span class="p">(</span><span class="nb">id</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="kc">None</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">    <span class="n">Row</span><span class="p">(</span><span class="nb">id</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="mi">40</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">    <span class="n">Row</span><span class="p">(</span><span class="nb">id</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="p">]</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Create DataFrame</span>
</span></span><span class="line"><span class="cl"><span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Show the DataFrame</span>
</span></span><span class="line"><span class="cl"><span class="n">df</span><span class="o">.</span><span class="n">show</span><span class="p">()</span></span></span></code></pre></div>
<h3 id="aggregate-functions-in-pyspark">Aggregate Functions in PySpark</h3>
<ol>
<li><strong>Summation (<code>sum</code>)</strong> â€“ Adds up the values in a column.</li>
<li><strong>Average (<code>avg</code>)</strong> â€“ Computes the average of values in a column.</li>
<li><strong>Count (<code>count</code>)</strong> â€“ Counts the number of non-null values in a column.</li>
<li><strong>Maximum (<code>max</code>) / Minimum (<code>min</code>)</strong> â€“ Finds the highest and lowest values.</li>
<li><strong>Distinct Count (<code>countDistinct</code>)</strong> â€“ Counts unique values in a column.</li>
</ol>
<h3 id="notes">Notes</h3>
<ul>
<li>
<p><strong>Handling Nulls</strong>:</p>
<ul>
<li><code>count()</code> counts only <strong>non-null</strong> values.</li>
<li><code>sum()</code>, <code>avg()</code>, <code>max()</code>, and <code>min()</code> ignore null values.</li>
</ul>
</li>
<li>
<p><strong>Performance</strong>:<br>
Aggregate functions can be expensive on large datasets; partitioning improves performance.</p>
</li>
<li>
<p><strong>Use Cases</strong>:</p>
<ul>
<li><strong>Summation</strong>: Total sales, total revenue.</li>
<li><strong>Average</strong>: Average sales per day.</li>
<li><strong>Count</strong>: Number of transactions.</li>
<li><strong>Max/Min</strong>: Highest and lowest values (e.g., max sales in a day).</li>
<li><strong>Distinct Count</strong>: Unique customers, unique products.</li>
</ul>
</li>
</ul>
<hr>
<h2 id="advanced-aggregation-functions">Advanced Aggregation Functions</h2>
<h3 id="sample-data-1">Sample Data</h3>
<div class="highlight wrap-code" dir="auto"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">pyspark.sql</span> <span class="kn">import</span> <span class="n">SparkSession</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">pyspark.sql</span> <span class="kn">import</span> <span class="n">functions</span> <span class="k">as</span> <span class="n">F</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">pyspark.sql.types</span> <span class="kn">import</span> <span class="n">StructType</span><span class="p">,</span> <span class="n">StructField</span><span class="p">,</span> <span class="n">StringType</span><span class="p">,</span> <span class="n">IntegerType</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Create Spark session</span>
</span></span><span class="line"><span class="cl"><span class="n">spark</span> <span class="o">=</span> <span class="n">SparkSession</span><span class="o">.</span><span class="n">builder</span><span class="o">.</span><span class="n">appName</span><span class="p">(</span><span class="s2">&#34;AggregationExamples&#34;</span><span class="p">)</span><span class="o">.</span><span class="n">getOrCreate</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Sample data</span>
</span></span><span class="line"><span class="cl"><span class="n">data</span> <span class="o">=</span> <span class="p">[</span>
</span></span><span class="line"><span class="cl">    <span class="p">(</span><span class="s2">&#34;HR&#34;</span><span class="p">,</span> <span class="mi">10000</span><span class="p">,</span> <span class="mi">500</span><span class="p">,</span> <span class="s2">&#34;John&#34;</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">    <span class="p">(</span><span class="s2">&#34;Finance&#34;</span><span class="p">,</span> <span class="mi">20000</span><span class="p">,</span> <span class="mi">1500</span><span class="p">,</span> <span class="s2">&#34;Doe&#34;</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">    <span class="p">(</span><span class="s2">&#34;HR&#34;</span><span class="p">,</span> <span class="mi">15000</span><span class="p">,</span> <span class="mi">1000</span><span class="p">,</span> <span class="s2">&#34;Alice&#34;</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">    <span class="p">(</span><span class="s2">&#34;Finance&#34;</span><span class="p">,</span> <span class="mi">25000</span><span class="p">,</span> <span class="mi">2000</span><span class="p">,</span> <span class="s2">&#34;Eve&#34;</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">    <span class="p">(</span><span class="s2">&#34;HR&#34;</span><span class="p">,</span> <span class="mi">20000</span><span class="p">,</span> <span class="mi">1500</span><span class="p">,</span> <span class="s2">&#34;Mark&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="p">]</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Define schema</span>
</span></span><span class="line"><span class="cl"><span class="n">schema</span> <span class="o">=</span> <span class="n">StructType</span><span class="p">([</span>
</span></span><span class="line"><span class="cl">    <span class="n">StructField</span><span class="p">(</span><span class="s2">&#34;department&#34;</span><span class="p">,</span> <span class="n">StringType</span><span class="p">(),</span> <span class="kc">True</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">    <span class="n">StructField</span><span class="p">(</span><span class="s2">&#34;salary&#34;</span><span class="p">,</span> <span class="n">IntegerType</span><span class="p">(),</span> <span class="kc">True</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">    <span class="n">StructField</span><span class="p">(</span><span class="s2">&#34;bonus&#34;</span><span class="p">,</span> <span class="n">IntegerType</span><span class="p">(),</span> <span class="kc">True</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">    <span class="n">StructField</span><span class="p">(</span><span class="s2">&#34;employee_name&#34;</span><span class="p">,</span> <span class="n">StringType</span><span class="p">(),</span> <span class="kc">True</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="p">])</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Create DataFrame</span>
</span></span><span class="line"><span class="cl"><span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">schema</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">df</span><span class="o">.</span><span class="n">show</span><span class="p">()</span></span></span></code></pre></div>
<h3 id="1-grouped-aggregation">1. Grouped Aggregation</h3>
<p>Perform aggregation within groups based on a column.</p>
<ul>
<li><strong><code>sum()</code></strong> â†’ Adds values within the group.</li>
<li><strong><code>avg()</code></strong> â†’ Computes group average.</li>
<li><strong><code>max()</code></strong> â†’ Finds maximum value.</li>
<li><strong><code>min()</code></strong> â†’ Finds minimum value.</li>
</ul>
<h3 id="2-multiple-aggregations">2. Multiple Aggregations</h3>
<p>Perform several aggregations in one step.</p>
<ul>
<li><strong><code>count()</code></strong> â†’ Number of rows in each group.</li>
<li><strong><code>avg()</code></strong> â†’ Average of values.</li>
<li><strong><code>max()</code></strong> â†’ Maximum value in group.</li>
</ul>
<h3 id="3-concatenate-strings">3. Concatenate Strings</h3>
<ul>
<li><strong><code>concat_ws()</code></strong> â†’ Concatenates string values within a column, separated by a delimiter (<code>,</code>).</li>
</ul>
<h3 id="4-first-and-last">4. First and Last</h3>
<ul>
<li><strong><code>first()</code></strong> â†’ Retrieves the first value of a column in a group.</li>
<li><strong><code>last()</code></strong> â†’ Retrieves the last value of a column in a group.</li>
</ul>
<h3 id="5-standard-deviation-and-variance">5. Standard Deviation and Variance</h3>
<ul>
<li><strong><code>stddev()</code></strong> â†’ Standard deviation of values.</li>
<li><strong><code>variance()</code></strong> â†’ Variance of values.</li>
</ul>
<h3 id="6-aggregation-with-alias">6. Aggregation with Alias</h3>
<ul>
<li><strong><code>.alias()</code></strong> â†’ Rename the result columns after aggregation.</li>
</ul>
<h3 id="7-sum-of-distinct-values">7. Sum of Distinct Values</h3>
<ul>
<li><strong><code>sumDistinct()</code></strong> â†’ Sums only <strong>unique values</strong> in a column (avoids double-counting duplicates).</li>
</ul>
<h3 id="-summary">ðŸ“Œ Summary</h3>
<ul>
<li>
<p>Use basic aggregations (<code>sum</code>, <code>avg</code>, <code>count</code>, <code>max</code>, <code>min</code>, <code>countDistinct</code>) for general metrics.</p>
</li>
<li>
<p>Apply advanced aggregations (<code>grouped</code>, <code>concat_ws</code>, <code>first</code>, <code>last</code>, <code>stddev</code>, <code>variance</code>, <code>sumDistinct</code>) for deeper analysis.</p>
</li>
<li>
<p>Always consider <strong>null handling</strong> and <strong>performance optimizations</strong> when using aggregate functions in PySpark.</p>
</li>
</ul>

  <footer class="footline">
  </footer>
</article>
        </div>
      </main>
    </div>
    <script src="/js/clipboard/clipboard.min.js?1759986780" defer></script>
    <script src="/js/perfect-scrollbar/perfect-scrollbar.min.js?1759986780" defer></script>
    <script src="/js/theme.js?1759986780" defer></script>
  </body>
</html>
